{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21834,
     "status": "ok",
     "timestamp": 1576704631813,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "PDot0E9yMDMr",
    "outputId": "ea12bdb0-619d-41c0-b4ed-aee89d4ec98e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# # %matplotlib inline\n",
    "# %cd /content/gdrive/My Drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xDRjtcFsL5B6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim import Adam, Adagrad \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4547,
     "status": "ok",
     "timestamp": 1576704643230,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "YwEZpT36lR9Q",
    "outputId": "5d01fd08-eced-42f0-ae1c-7e2ec5d60f1a"
   },
   "outputs": [],
   "source": [
    "# % ls 'Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2arqoy5aME9g"
   },
   "outputs": [],
   "source": [
    "# sys.path.insert(0, \"Colab Notebooks/NLP_Projects/Abstractive_Summarization/\")\n",
    "import config\n",
    "from data import Vocab, abstract2sents\n",
    "from batcher import Example, Batch\n",
    "from model import Model\n",
    "\n",
    "from utils import get_input_from_batch, get_output_from_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_JlMwvwfL5B_"
   },
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cGu8Md5L5CA"
   },
   "outputs": [],
   "source": [
    "def preprocessing_file(file_path):\n",
    "\n",
    "    keys = ['article_id', 'article_text', 'abstract_text', 'labels', 'section_names', 'sections']\n",
    "    content_list = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for l in tqdm(f.readlines()):\n",
    "\n",
    "            content = [item for item in l.split(\"\\\"\")]\n",
    "            item_dict = {}\n",
    "\n",
    "            for item in content[1:]:\n",
    "                if item in keys:\n",
    "                    item_dict[item] = []\n",
    "                    key_ = item\n",
    "                    if item == 'sections':\n",
    "                        count_sections = -1\n",
    "\n",
    "                else:\n",
    "                    if key_ != 'sections':\n",
    "                        if item not in ['], ', ', ', ': [[', ']]}\\n', '{', ': [', ': '] :\n",
    "                            item_dict[key_].append(item)\n",
    "                    else:\n",
    "                        if item in [': [[',  '], [']:\n",
    "                            item_dict[key_].append([])\n",
    "                            count_sections += 1\n",
    "                        elif item not in [']]}\\n', ', ' ]:\n",
    "                            item_dict[key_][count_sections].append(item)\n",
    "            \n",
    "            if len(item_dict['article_text']) > 1:\n",
    "                item_dict['abstract_text'] = \" \".join(item_dict['abstract_text'] )\n",
    "                item_dict['abstract_text'] = [sent.strip() for sent in abstract2sents(item_dict['abstract_text'])]\n",
    "                content_list.append(item_dict)\n",
    "\n",
    "        \n",
    "    return content_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3959,
     "status": "ok",
     "timestamp": 1576706915467,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "Bd1SXwzlL5CD",
    "outputId": "b4aece4a-5208-44c3-9262-e43a5812f95b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119924/119924 [00:21<00:00, 5680.73it/s]\n",
      "100%|██████████| 6633/6633 [00:01<00:00, 3401.42it/s]\n"
     ]
    }
   ],
   "source": [
    "data_ = {}\n",
    "data_[\"train\"] = preprocessing_file(\"../pubmed-release/train.txt\")\n",
    "data_[\"val\"] = preprocessing_file(\"../pubmed-release/val.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfRpdI-vL5CG"
   },
   "source": [
    "#### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59637,
     "status": "ok",
     "timestamp": 1576704723936,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "q-mZV256L5CH",
    "outputId": "fa5247a9-e3fc-48d5-f815-6a8b57954030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished constructing vocabulary of 50004 total words. Last word added: hpse\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(\"../pubmed-release/vocab\", 50100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59314,
     "status": "ok",
     "timestamp": 1576704723938,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "DN-pDktLL5CJ",
    "outputId": "c1862596-f15a-43b8-d04a-986855e1e493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word2id(\"medical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vShPLbgML5CM"
   },
   "source": [
    "#### Form Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzjqFrlaL5CM"
   },
   "outputs": [],
   "source": [
    "# examples_batch = [Example(article=\"\".join(item['article_text']), \n",
    "#                           abstract_sentences=item['abstract_text'], \n",
    "#                           vocab=vocab) \n",
    "#                   for item in data[\"train\"][:16] ]\n",
    "\n",
    "# batch = Batch(example_list=examples_batch, vocab=vocab, batch_size=16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ce85FRarL5CO"
   },
   "outputs": [],
   "source": [
    "# config.max_enc_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZlTionOxL5CQ"
   },
   "outputs": [],
   "source": [
    "class Batcher(object):\n",
    "    def __init__(self, data_dicts, vocab, batch_size, shuffle=True):\n",
    "        self.data_dicts = data_dicts\n",
    "        self.vocab = vocab\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if self.shuffle:\n",
    "            inds = np.arange(len(self.data_dicts))\n",
    "            np.random.shuffle(inds)\n",
    "            self.data_dicts = [self.data_dicts[ind] for ind in list(inds)]\n",
    "            \n",
    "        self.start_batch = 0\n",
    "    def next_batch(self):\n",
    "        \n",
    "        if self.start_batch + self.batch_size >= len(self.data_dicts):\n",
    "            return None\n",
    "\n",
    "        example_list = [Example(article=\" \".join(self.data_dicts[self.start_batch + i]['article_text']), \n",
    "                          abstract_sentences=self.data_dicts[self.start_batch + i]['abstract_text'], \n",
    "                          vocab=self.vocab) \n",
    "                        for i in range(self.batch_size)]\n",
    "        \n",
    "        batch = Batch(example_list=example_list, \n",
    "                      vocab=self.vocab, \n",
    "                      batch_size=self.batch_size) \n",
    "        \n",
    "        self.start_batch += self.batch_size\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cNv0zsqL5CS"
   },
   "outputs": [],
   "source": [
    "def calc_running_avg_loss(loss, running_avg_loss, step, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "\n",
    "    return running_avg_loss\n",
    "\n",
    "def train_model(model, batcher, optimizer, scheduler, N_epoch, use_cuda=False, start_iter=0, running_avg_loss=0):\n",
    "    train_history = {}\n",
    "    df_history = pd.DataFrame(columns=[\"epoch\", \"itr\", \"loss\", \"running_loss\"])\n",
    "    \n",
    "    train_dir = \"weights/train_{}\".format(strftime(\"%Y-%m-%d_%H:%M:%S\", gmtime()))\n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "    for epoch in range(N_epoch):\n",
    "        train_history[epoch] = {\"loss\":[], \"running_loss\":[]}\n",
    "        itr = 0\n",
    "        while True:\n",
    "            if itr % 1000 == 999:\n",
    "                try:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'itr': itr,\n",
    "                        'encoder': model.encoder.state_dict(),\n",
    "                        'decoder': model.decoder.state_dict(),\n",
    "                        'reduce_state': model.reduce_state.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': loss}, train_dir + \"/weights.loss_{:.3f}.pt\".format(loss))\n",
    "                except:\n",
    "                    print(\"Failed to save\")\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "            batch = batcher.next_batch()\n",
    "            if batch:\n",
    "                loss = train_one_batch(model, optimizer, batch, use_cuda)\n",
    "                train_history[epoch][\"loss\"].append(loss)\n",
    "                \n",
    "                running_avg_loss = calc_running_avg_loss(loss, running_avg_loss, iter)\n",
    "                train_history[epoch][\"running_loss\"].append(running_avg_loss)\n",
    "\n",
    "                df_history.loc[df_history.shape[0]] = [epoch+1, itr+1, loss, running_avg_loss]\n",
    "                df_history.to_csv(train_dir + \"/train_history.csv\", index=False)\n",
    "\n",
    "                if itr % 10 == 9:\n",
    "                    print(\"{} epoch, {} itr: loss = {}\".format(epoch +1, itr+1, running_avg_loss))\n",
    "\n",
    "                itr += 1\n",
    "            else:\n",
    "                batcher.start_batch = 0\n",
    "                break\n",
    "    return model, train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIIZAEKxL5CU"
   },
   "outputs": [],
   "source": [
    "def train_one_batch(model, optimizer, batch, use_cuda=False):\n",
    "    \n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, c_t_1, coverage = \\\n",
    "        get_input_from_batch(batch, use_cuda)\n",
    "    dec_batch, dec_padding_mask, max_dec_len, dec_lens_var, target_batch = \\\n",
    "        get_output_from_batch(batch, use_cuda)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    encoder_outputs, encoder_feature, encoder_hidden = model.encoder(enc_batch, enc_lens)\n",
    "    s_t_1 = model.reduce_state(encoder_hidden)\n",
    "\n",
    "    step_losses = []\n",
    "    for di in range(min(max_dec_len, config.max_dec_steps)):\n",
    "        \n",
    "        y_t_1 = dec_batch[:, di]  # Teacher forcing\n",
    "        final_dist, s_t_1,  c_t_1, attn_dist, p_gen, next_coverage = model.decoder(y_t_1, s_t_1,\n",
    "                                                    encoder_outputs, encoder_feature, enc_padding_mask, c_t_1,\n",
    "                                                    extra_zeros, enc_batch_extend_vocab,\n",
    "                                                                       coverage, di)\n",
    "        target = target_batch[:, di]\n",
    "        gold_probs = torch.gather(final_dist, 1, target.unsqueeze(1)).squeeze()\n",
    "        step_loss = -torch.log(gold_probs + config.eps)\n",
    "        if config.is_coverage:\n",
    "            step_coverage_loss = torch.sum(torch.min(attn_dist, coverage), 1)\n",
    "            step_loss = step_loss + config.cov_loss_wt * step_coverage_loss\n",
    "            coverage = next_coverage\n",
    "\n",
    "        step_mask = dec_padding_mask[:, di]\n",
    "        step_loss = step_loss * step_mask\n",
    "        step_losses.append(step_loss)\n",
    "\n",
    "    sum_losses = torch.sum(torch.stack(step_losses, 1), 1)\n",
    "    batch_avg_loss = sum_losses/dec_lens_var\n",
    "    loss = torch.mean(batch_avg_loss)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    norm = clip_grad_norm_(model.encoder.parameters(), config.max_grad_norm)\n",
    "    clip_grad_norm_(model.decoder.parameters(), config.max_grad_norm)\n",
    "    clip_grad_norm_(model.reduce_state.parameters(), config.max_grad_norm)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JB9n-FDsL5CW"
   },
   "outputs": [],
   "source": [
    "def setup_train(model_file_path=None):\n",
    "    model = Model(model_file_path)\n",
    "\n",
    "    params = list(model.encoder.parameters()) + list(model.decoder.parameters()) + \\\n",
    "             list(model.reduce_state.parameters())\n",
    "    initial_lr = config.lr_coverage if config.is_coverage else config.lr\n",
    "    optimizer = Adagrad(params, lr=initial_lr, initial_accumulator_value=config.adagrad_init_acc)\n",
    "    scheduler = StepLR(optimizer, step_size=7, gamma=0.5)\n",
    "\n",
    "    start_iter, start_loss = 0, 0\n",
    "\n",
    "    if model_file_path is not None:\n",
    "        state = torch.load(model_file_path, map_location= lambda storage, location: storage)\n",
    "        start_iter = state['iter']\n",
    "        start_loss = state['current_loss']\n",
    "\n",
    "        if not config.is_coverage:\n",
    "            optimizer.load_state_dict(state['optimizer'])\n",
    "            if use_cuda:\n",
    "                for state in optimizer.state.values():\n",
    "                    for k, v in state.items():\n",
    "                        if torch.is_tensor(v):\n",
    "                            state[k] = v.cuda()\n",
    "\n",
    "    return model, optimizer, scheduler, start_iter, start_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NF6n1WdEL5CY"
   },
   "outputs": [],
   "source": [
    "config.pointer_gen = True\n",
    "config.lr = 0.1\n",
    "model, optimizer, scheduler, start_iter, start_loss = setup_train()\n",
    "batcher_train = Batcher(data_[\"train\"], vocab, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"weights/train_2019-12-19_00:15:56/weights.loss_3.535.pt\")\n",
    "model.encoder.load_state_dict(checkpoint['encoder'])\n",
    "model.decoder.load_state_dict(checkpoint['decoder'])\n",
    "model.reduce_state.load_state_dict(checkpoint['reduce_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FifxQynXL5Ca",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/.conda/envs/pytorch1_3/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/artem/.conda/envs/pytorch1_3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch, 10 itr: loss = 3.9310953600291323\n",
      "1 epoch, 20 itr: loss = 3.9662183771015367\n",
      "1 epoch, 30 itr: loss = 3.9720924995878724\n",
      "1 epoch, 40 itr: loss = 3.9567189146835293\n",
      "1 epoch, 50 itr: loss = 3.9482634328228516\n",
      "1 epoch, 60 itr: loss = 3.941840803266103\n",
      "1 epoch, 70 itr: loss = 3.920153228020532\n",
      "1 epoch, 80 itr: loss = 3.9081718429653134\n",
      "1 epoch, 90 itr: loss = 3.896719419912846\n",
      "1 epoch, 100 itr: loss = 3.8984959900711647\n",
      "1 epoch, 110 itr: loss = 3.8942459460996903\n"
     ]
    }
   ],
   "source": [
    "model_point, train_history_point = train_model(model, batcher_train, optimizer, scheduler, N_epoch=10, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_history.csv      weights.loss_3.941.pt  weights.loss_4.115.pt\r\n",
      "weights.loss_3.535.pt  weights.loss_3.970.pt  weights.loss_4.149.pt\r\n",
      "weights.loss_3.654.pt  weights.loss_4.111.pt  weights.loss_4.323.pt\r\n"
     ]
    }
   ],
   "source": [
    "! ls weights/train_2019-12-19_00:15:56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8a97n8BK7X_B"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCOayGkQDY_W"
   },
   "outputs": [],
   "source": [
    "config.pointer_gen = True\n",
    "model = Model(is_eval=True)\n",
    "use_cuda = True\n",
    "\n",
    "batcher = Batcher(data_[\"val\"], vocab, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1576707073336,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "1oGAAymEDbXt",
    "outputId": "7c86835a-d1a9-4896-d614-285930ca30b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"weights/train_2019-12-19_01:58:07/weights.loss_3.420.pt\")\n",
    "model.encoder.load_state_dict(checkpoint['encoder'])\n",
    "model.decoder.load_state_dict(checkpoint['decoder'])\n",
    "model.reduce_state.load_state_dict(checkpoint['reduce_state'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgwyVPwGBhAF"
   },
   "outputs": [],
   "source": [
    "def evaluate_batch(model, batch):\n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, c_t_1, coverage = \\\n",
    "        get_input_from_batch(batch, use_cuda)\n",
    "    dec_batch, dec_padding_mask, max_dec_len, dec_lens_var, target_batch = \\\n",
    "        get_output_from_batch(batch, use_cuda)\n",
    "\n",
    "    encoder_outputs, encoder_feature, encoder_hidden = model.encoder(enc_batch, enc_lens)\n",
    "    s_t_1 = model.reduce_state(encoder_hidden)\n",
    "\n",
    "    batch_prediction, batch_target = [], []\n",
    "\n",
    "    for di in range(min(max_dec_len, config.max_dec_steps)):\n",
    "        y_t_1 = dec_batch[:, di]  # Teacher forcing\n",
    "        final_dist, s_t_1, c_t_1,attn_dist, p_gen, next_coverage = model.decoder(y_t_1, s_t_1,\n",
    "                                                    encoder_outputs, encoder_feature, enc_padding_mask, c_t_1,\n",
    "                                                    extra_zeros, enc_batch_extend_vocab, coverage, di)\n",
    "        \n",
    "        target = target_batch[:, di]\n",
    "        batch_target.append(target[0].item())\n",
    "\n",
    "        prediction = torch.argmax(final_dist, dim=1)\n",
    "        batch_prediction.append(prediction[0].item())\n",
    "        \n",
    "#         print(final_dist.shape)\n",
    "\n",
    "        gold_probs = torch.gather(final_dist, 1, target.unsqueeze(1)).squeeze()\n",
    "\n",
    "    step = 20\n",
    "    # Target \n",
    "    batch_target = [vocab.id2word(b) for b in batch_target if b < 50004]\n",
    "    print(\" --- TARGET ---\")\n",
    "    for i in range(0, len(batch_target), step):\n",
    "        print(\" \".join(batch_target[i:min(i+step, len(batch_target))] ))\n",
    "\n",
    "    # Prediction\n",
    "    batch_prediction = [vocab.id2word(b) for b in batch_prediction if b < 50004]\n",
    "    print(\" --- PREDICTION --- \")\n",
    "    for i in range(0, len(batch_prediction), step):\n",
    "        print(\" \".join(batch_prediction[i:min(i+step, len(batch_prediction))] ))\n",
    "\n",
    "\n",
    "def evaluate(model, batcher, N):\n",
    "\n",
    "    for _ in range(N):\n",
    "        print(\"-\"*40)\n",
    "        batch = batcher.next_batch()\n",
    "        evaluate_batch(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1299,
     "status": "ok",
     "timestamp": 1576707115329,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "ZC4WtjXeBhJo",
    "outputId": "72ff23ac-8855-4939-f32b-47389b3ecb19",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      " --- TARGET ---\n",
      "we describe the first reported cases of invasive type e haemophilus influenzae disease in italy . all five cases occurred\n",
      "in adults . the isolates were susceptible to ampicillin and eight other antimicrobial agents . molecular analysis showed two distinct\n",
      "type e strains circulating in italy , both containing a single copy of the locus . [STOP]\n",
      " --- PREDICTION --- \n",
      "[UNK] report a first case case of meningitis meningitis e - influenzae strains ( elderly . the the cases were\n",
      "in young with the patient were found to the , the of cases agents . [STOP] analysis revealed that distinct\n",
      "genes e strain . in the . which with the [UNK] - number the locus gene . [STOP]\n",
      "----------------------------------------\n",
      " --- TARGET ---\n",
      "introduction : : bone disease , melting wax syndrome , disease ) is a rare chronic bone disorder , first\n",
      "described in by and . men and women are equally affected , and no hereditary features have been discovered .\n",
      "onset is insidious , and most common symptom is pain . most common part of bone is diaphysis of the\n",
      "long bone of lower limb rarely the axial skeleton . classical radiological appearance of flowing resembling hardened wax that has\n",
      "down the side of a [UNK] report : a 35 years old\n",
      " --- PREDICTION --- \n",
      ": bone bone disease , melting wax syndrome , disease , is a rare chronic bone disorder , first described\n",
      "in by and . men and women are equally affected , and no hereditary features have been discovered . most\n",
      "of equally , and no common part is diaphysis . most common part of bone is diaphysis of the long\n",
      "bone of lower limb rarely the axial skeleton . most radiological appearance of flowing resembling hardened wax that has down\n",
      "the side of a [UNK] : a 35 years old\n",
      "----------------------------------------\n",
      " --- TARGET ---\n",
      "a [UNK] - containing [UNK] - [UNK] - [UNK] - [UNK] ) polymer , acting as a light - harvesting\n",
      "ligand system , was synthesized and coupled to an [UNK] complex designed for photocatalytic [UNK] reduction . the material ,\n",
      "which absorbs over a wide spectral range , was characterized by using various analytical techniques , confirming its chemical structure\n",
      "and properties . the dielectric function of the material was determined from spectroscopic [UNK] measurements . photocatalytic reduction of nucleotide\n",
      "redox cofactors under visible light irradiation ( [UNK] nm\n",
      " --- PREDICTION --- \n",
      "the - based - - - based - based - is oligomeric and as a redox - harvesting of ,\n",
      ", was applied . [UNK] with the - - - of to the - - . the the [UNK] of\n",
      "[UNK] are the the redox range time of the found by by the a and , which the potential properties\n",
      "and and [UNK] of the of the found by by the and and . the of of the - -\n",
      ", the - - was [UNK] ) )\n",
      "----------------------------------------\n",
      " --- TARGET ---\n",
      "sling procedures are a widely proven treatment for stress urinary incontinence . the aim of this prospective study was to\n",
      "evaluate the effect of the tape on female sexual functioning . fifty - four women treated for stress urinary incontinence\n",
      "with tape filled out self - administered questionnaires on quality of life , urinary incontinence , and sexual function prior\n",
      "to surgery and 6 weeks and 12 months postoperatively . preoperatively , 40 women ( 78% ) were sexually active\n",
      ". there were no significant postoperative changes regarding frequency of sexual activity , sexual desire , and problems\n",
      " --- PREDICTION --- \n",
      "[UNK] procedures have a standard used minimally of treatment urinary incontinence . the aim of this study observational was to\n",
      "evaluate the effect of tot tape ( sexual and functioning and methods - four patients were with stress urinary incontinence\n",
      "were a tape ( with for - up stress were the of life , social incontinence , and sexual satisfaction\n",
      ". to the . sexual months . were months . . the were the , were n ) were selected\n",
      "urinary tension the were no significant difference complications in the of sexual functioning . and functioning , and sexual\n",
      "----------------------------------------\n",
      " --- TARGET ---\n",
      "a 63-year - old male presented with sudden increase in size of a right inguinal swelling which was present for\n",
      "the past 10 years . clinical diagnosis of inguinal soft tissue mass / lymph node enlargement was made and patient\n",
      "was investigated further for a conclusive diagnosis . ultrasound examination suggested it to be a lymph node and guided fine\n",
      "needle aspiration cytology was performed . cytology was suggestive of a reactive lymph node . subsequently , an excision biopsy\n",
      "was performed that revealed a granular cell tumor with many lymphoid aggregates . on reviewing the , we realised\n",
      " --- PREDICTION --- \n",
      "granular 63-year - old male presented with swelling increase in size since the sudden inguinal region . was felt in\n",
      "swelling right 10 years . on examination was granular granular tissue was was granular node was was performed . was\n",
      "was performed . . granular patient follow . [STOP] - revealed a to be a rare node on granular granular\n",
      "- with . . performed . [STOP] was performed of granular granular lymph node on [STOP] , the excision biopsy\n",
      "was performed which showed skin reactive cell tumor . a granular cells . [STOP] the , case of a report\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, batcher, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWutEjidL5Cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RnTl9vxY9wkn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2888,
     "status": "ok",
     "timestamp": 1576666487903,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "ubeXHSkUL5Ch",
    "outputId": "eaa4dc3b-10c7-4348-e512-d596b595be99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 18 10:54:46 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   75C    P0    27W /  75W |   3689MiB /  7611MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 706,
     "status": "error",
     "timestamp": 1576705592507,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "03t35YHU6Bgh",
    "outputId": "6d050f16-0668-4afd-ee42-6f4e9da02889"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-cb68e37e08f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50004\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/NLP_Projects/Abstractive_Summarization/data.py\u001b[0m in \u001b[0;36mid2word\u001b[0;34m(self, word_id)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_to_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Id not found in vocab: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Id not found in vocab: 50004"
     ]
    }
   ],
   "source": [
    "vocab.id2word(50004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1576705678116,
     "user": {
      "displayName": "Елизавета Лазарева",
      "photoUrl": "",
      "userId": "06665894970325519130"
     },
     "user_tz": -180
    },
    "id": "zr5ho2OC-Xe_",
    "outputId": "f3ebad80-4d59-4111-9df0-2a75d914fcb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[UNK]', '[PAD]', '[START]', '[STOP]')"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.id2word(0), vocab.id2word(1), vocab.id2word(2), vocab.id2word(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUxGkSyd-odt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
